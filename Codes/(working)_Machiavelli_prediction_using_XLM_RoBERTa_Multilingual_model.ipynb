{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1d39c810e9a440eca3f698e2d5510033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4edaae57eb6b4ac19eec75a4bf92e4ce",
              "IPY_MODEL_f0ddbed0006b46f6b673ed1ce6d17789",
              "IPY_MODEL_7d279d2d7aff49a89c834c7cb236fb76"
            ],
            "layout": "IPY_MODEL_2f15f0bdcd674cb08400e95174e12452"
          }
        },
        "4edaae57eb6b4ac19eec75a4bf92e4ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0473d72da0a64198b87be4e1a81073a0",
            "placeholder": "​",
            "style": "IPY_MODEL_f62f58ea4e61448aa0bb7ab037314d3a",
            "value": "Downloading (…)tencepiece.bpe.model: 100%"
          }
        },
        "f0ddbed0006b46f6b673ed1ce6d17789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f05b4391d4146b48ac3ffe7ddf7d759",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15d333d506934956a9a1e62ac8e9d11f",
            "value": 5069051
          }
        },
        "7d279d2d7aff49a89c834c7cb236fb76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_deae2ecc6bd54e6488554e776e422c78",
            "placeholder": "​",
            "style": "IPY_MODEL_0f76fd3f7f76494c910458fa4772fe3a",
            "value": " 5.07M/5.07M [00:01&lt;00:00, 3.46MB/s]"
          }
        },
        "2f15f0bdcd674cb08400e95174e12452": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0473d72da0a64198b87be4e1a81073a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f62f58ea4e61448aa0bb7ab037314d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f05b4391d4146b48ac3ffe7ddf7d759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15d333d506934956a9a1e62ac8e9d11f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "deae2ecc6bd54e6488554e776e422c78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f76fd3f7f76494c910458fa4772fe3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec1ac978cc644959915de165c0b8eac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07162fae5d084c7b8570ffae478cdf78",
              "IPY_MODEL_2dda46ab510642ca98b74ab9937a68b8",
              "IPY_MODEL_5e8b2952387349648609e184ed8e5834"
            ],
            "layout": "IPY_MODEL_75bf3ca925be43d7ae1450d5b4aeeb07"
          }
        },
        "07162fae5d084c7b8570ffae478cdf78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c856d3bf2a23495799a1ec9c372d8322",
            "placeholder": "​",
            "style": "IPY_MODEL_413f83176d7c49cdbab5332db84ebb1e",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "2dda46ab510642ca98b74ab9937a68b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93ee724fc271486db79ec873441e9566",
            "max": 615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db55fda2a3c144099813a0f8cdfa70f4",
            "value": 615
          }
        },
        "5e8b2952387349648609e184ed8e5834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_290c926bba4a4fb5bd87dd26032bc984",
            "placeholder": "​",
            "style": "IPY_MODEL_3d11b46e3aaf46869c329693b9ce7861",
            "value": " 615/615 [00:00&lt;00:00, 26.8kB/s]"
          }
        },
        "75bf3ca925be43d7ae1450d5b4aeeb07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c856d3bf2a23495799a1ec9c372d8322": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "413f83176d7c49cdbab5332db84ebb1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93ee724fc271486db79ec873441e9566": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db55fda2a3c144099813a0f8cdfa70f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "290c926bba4a4fb5bd87dd26032bc984": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d11b46e3aaf46869c329693b9ce7861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c86f382f9f074fbeb5f1ff1cd09343e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_898d8af4a7324c21885612734df7762e",
              "IPY_MODEL_2b11ad598a7843fbb1cd3f7d92b4727a",
              "IPY_MODEL_86ae1291eb53462db3e571c4a787c6d8"
            ],
            "layout": "IPY_MODEL_1ce3b0039f7f49e6a14ad03c7111215c"
          }
        },
        "898d8af4a7324c21885612734df7762e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ca1df3c5edf4a2fbc5ee43884eefe98",
            "placeholder": "​",
            "style": "IPY_MODEL_49b496fbb9d34ddead3703ac3d981a81",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "2b11ad598a7843fbb1cd3f7d92b4727a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d22f8cee19344fda3528eabd20fb90f",
            "max": 1115590446,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da36acd1a1ce4c058e20bf05ab907335",
            "value": 1115590446
          }
        },
        "86ae1291eb53462db3e571c4a787c6d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5938ae7223324ea6bd384bad962fe078",
            "placeholder": "​",
            "style": "IPY_MODEL_0ca198eb0aa44d4999a721fd4c0e9fc6",
            "value": " 1.12G/1.12G [00:04&lt;00:00, 248MB/s]"
          }
        },
        "1ce3b0039f7f49e6a14ad03c7111215c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ca1df3c5edf4a2fbc5ee43884eefe98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49b496fbb9d34ddead3703ac3d981a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d22f8cee19344fda3528eabd20fb90f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da36acd1a1ce4c058e20bf05ab907335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5938ae7223324ea6bd384bad962fe078": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ca198eb0aa44d4999a721fd4c0e9fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentencepiece"
      ],
      "metadata": {
        "id": "_CYAyy7ig1oZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers"
      ],
      "metadata": {
        "id": "khb8IIn70URQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers"
      ],
      "metadata": {
        "id": "ZWZ4in3e746X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocessing Dataset"
      ],
      "metadata": {
        "id": "KIZlDxYg0nfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "jI530eBP0rty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils import data\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "rcParams['figure.figsize'] = 8, 6\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztG9LfCf7ul8",
        "outputId": "f4d70db6-42f2-4a9b-ad73-c571b43699fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f09eb012230>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/final_dataset_appendedEverything.csv\")\n",
        "df.dropna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "id": "cABTRzly0pCX",
        "outputId": "0e443488-cd40-4318-ced3-bade9ae48624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0.2  Unnamed: 0.1  level_0  index  Unnamed: 0  \\\n",
              "0                0             0        0      0           0   \n",
              "1                1             1        2      2           2   \n",
              "2                2             2        5      5           5   \n",
              "3                3             3        6      6           6   \n",
              "4                4             4       10     10          10   \n",
              "...            ...           ...      ...    ...         ...   \n",
              "8687          8687          8687    12710  12745       12745   \n",
              "8688          8688          8688    12711  12746       12746   \n",
              "8689          8689          8689    12713  12748       12748   \n",
              "8690          8690          8690    12714  12749       12749   \n",
              "8691          8691          8691    12715  12750       12750   \n",
              "\n",
              "                                                   post  Mach  LSRP12  LSRP2  \\\n",
              "0                                 my heart my soul..T-T    68     1.3    2.5   \n",
              "1                 Free speech is a joke in this country    68     1.3    2.5   \n",
              "2     Make 500 sequels I don't care.Make another Jus...    68     1.3    2.5   \n",
              "3     Everybody wants a piece of the politically cor...    68     1.3    2.5   \n",
              "4                       And that's how a movement dies.    68     1.3    2.5   \n",
              "...                                                 ...   ...     ...    ...   \n",
              "8687                    TWO SUPERHUMANS IN ONE FRAME <3    53     1.9    3.1   \n",
              "8688  Man!!!\\nThe chase- UNBELIEVABLE!! Mushi and Ri...    53     1.9    3.1   \n",
              "8689                                              <3 <3    53     1.9    3.1   \n",
              "8690                               Madrid Triumphs!! :D    53     1.9    3.1   \n",
              "8691                  A small piece of heaven on earth.    53     1.9    3.1   \n",
              "\n",
              "      NRSM  Person         dark_triad  eng_usage_ratio  bng_usage_ratio  \\\n",
              "0        3       2       mach, psycho       100.000000         0.000000   \n",
              "1        3       2       mach, psycho       100.000000         0.000000   \n",
              "2        3       2       mach, psycho        76.470588        17.647059   \n",
              "3        3       2       mach, psycho       100.000000         0.000000   \n",
              "4        3       2       mach, psycho        83.333333        16.666667   \n",
              "...    ...     ...                ...              ...              ...   \n",
              "8687    19     100  psycho, narcisist        71.428571        14.285714   \n",
              "8688    19     100  psycho, narcisist        33.333333        55.555556   \n",
              "8689    19     100  psycho, narcisist        50.000000         0.000000   \n",
              "8690    19     100  psycho, narcisist        50.000000        25.000000   \n",
              "8691    19     100  psycho, narcisist       100.000000         0.000000   \n",
              "\n",
              "      eng_switching_ratio  bng_switching_ratio  \n",
              "0                0.000000             0.000000  \n",
              "1                0.000000             0.000000  \n",
              "2               66.666667            33.333333  \n",
              "3                0.000000             0.000000  \n",
              "4               50.000000            50.000000  \n",
              "...                   ...                  ...  \n",
              "8687            50.000000            50.000000  \n",
              "8688            60.000000            40.000000  \n",
              "8689             0.000000             0.000000  \n",
              "8690           100.000000             0.000000  \n",
              "8691             0.000000             0.000000  \n",
              "\n",
              "[8692 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b7298629-e2f1-49df-867d-d2cc5f89b02b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0.2</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>level_0</th>\n",
              "      <th>index</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>post</th>\n",
              "      <th>Mach</th>\n",
              "      <th>LSRP12</th>\n",
              "      <th>LSRP2</th>\n",
              "      <th>NRSM</th>\n",
              "      <th>Person</th>\n",
              "      <th>dark_triad</th>\n",
              "      <th>eng_usage_ratio</th>\n",
              "      <th>bng_usage_ratio</th>\n",
              "      <th>eng_switching_ratio</th>\n",
              "      <th>bng_switching_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>my heart my soul..T-T</td>\n",
              "      <td>68</td>\n",
              "      <td>1.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>mach, psycho</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Free speech is a joke in this country</td>\n",
              "      <td>68</td>\n",
              "      <td>1.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>mach, psycho</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>Make 500 sequels I don't care.Make another Jus...</td>\n",
              "      <td>68</td>\n",
              "      <td>1.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>mach, psycho</td>\n",
              "      <td>76.470588</td>\n",
              "      <td>17.647059</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>33.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>Everybody wants a piece of the politically cor...</td>\n",
              "      <td>68</td>\n",
              "      <td>1.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>mach, psycho</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>And that's how a movement dies.</td>\n",
              "      <td>68</td>\n",
              "      <td>1.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>mach, psycho</td>\n",
              "      <td>83.333333</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>50.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8687</th>\n",
              "      <td>8687</td>\n",
              "      <td>8687</td>\n",
              "      <td>12710</td>\n",
              "      <td>12745</td>\n",
              "      <td>12745</td>\n",
              "      <td>TWO SUPERHUMANS IN ONE FRAME &lt;3</td>\n",
              "      <td>53</td>\n",
              "      <td>1.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>19</td>\n",
              "      <td>100</td>\n",
              "      <td>psycho, narcisist</td>\n",
              "      <td>71.428571</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>50.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8688</th>\n",
              "      <td>8688</td>\n",
              "      <td>8688</td>\n",
              "      <td>12711</td>\n",
              "      <td>12746</td>\n",
              "      <td>12746</td>\n",
              "      <td>Man!!!\\nThe chase- UNBELIEVABLE!! Mushi and Ri...</td>\n",
              "      <td>53</td>\n",
              "      <td>1.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>19</td>\n",
              "      <td>100</td>\n",
              "      <td>psycho, narcisist</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>55.555556</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>40.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8689</th>\n",
              "      <td>8689</td>\n",
              "      <td>8689</td>\n",
              "      <td>12713</td>\n",
              "      <td>12748</td>\n",
              "      <td>12748</td>\n",
              "      <td>&lt;3 &lt;3</td>\n",
              "      <td>53</td>\n",
              "      <td>1.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>19</td>\n",
              "      <td>100</td>\n",
              "      <td>psycho, narcisist</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8690</th>\n",
              "      <td>8690</td>\n",
              "      <td>8690</td>\n",
              "      <td>12714</td>\n",
              "      <td>12749</td>\n",
              "      <td>12749</td>\n",
              "      <td>Madrid Triumphs!! :D</td>\n",
              "      <td>53</td>\n",
              "      <td>1.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>19</td>\n",
              "      <td>100</td>\n",
              "      <td>psycho, narcisist</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8691</th>\n",
              "      <td>8691</td>\n",
              "      <td>8691</td>\n",
              "      <td>12715</td>\n",
              "      <td>12750</td>\n",
              "      <td>12750</td>\n",
              "      <td>A small piece of heaven on earth.</td>\n",
              "      <td>53</td>\n",
              "      <td>1.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>19</td>\n",
              "      <td>100</td>\n",
              "      <td>psycho, narcisist</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8692 rows × 16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7298629-e2f1-49df-867d-d2cc5f89b02b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b7298629-e2f1-49df-867d-d2cc5f89b02b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b7298629-e2f1-49df-867d-d2cc5f89b02b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = df['Mach'].mean()\n",
        "mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghD65GVg_ufA",
        "outputId": "8961672f-3118-4fa9-ff65-cc421369406b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15.771514035895075"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare(ratings):\n",
        "    rating = int(ratings)\n",
        "    if rating > 16:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "3zHdeloEAIUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Trait'] = df.Mach.apply(compare)"
      ],
      "metadata": {
        "id": "cbWXdV3ZAaek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "id": "bCgBclq5BY_H",
        "outputId": "52f7c7a4-3262-4c8d-d591-c47d95f7561e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0.2  Unnamed: 0.1  level_0  index  Unnamed: 0  \\\n",
              "0                0             0        0      0           0   \n",
              "1                1             1        2      2           2   \n",
              "2                2             2        5      5           5   \n",
              "3                3             3        6      6           6   \n",
              "4                4             4       10     10          10   \n",
              "...            ...           ...      ...    ...         ...   \n",
              "8687          8687          8687    12710  12745       12745   \n",
              "8688          8688          8688    12711  12746       12746   \n",
              "8689          8689          8689    12713  12748       12748   \n",
              "8690          8690          8690    12714  12749       12749   \n",
              "8691          8691          8691    12715  12750       12750   \n",
              "\n",
              "                                                   post  Mach  LSRP12  LSRP2  \\\n",
              "0                                 my heart my soul..T-T    68     1.3    2.5   \n",
              "1                 Free speech is a joke in this country    68     1.3    2.5   \n",
              "2     Make 500 sequels I don't care.Make another Jus...    68     1.3    2.5   \n",
              "3     Everybody wants a piece of the politically cor...    68     1.3    2.5   \n",
              "4                       And that's how a movement dies.    68     1.3    2.5   \n",
              "...                                                 ...   ...     ...    ...   \n",
              "8687                    TWO SUPERHUMANS IN ONE FRAME <3    53     1.9    3.1   \n",
              "8688  Man!!!\\nThe chase- UNBELIEVABLE!! Mushi and Ri...    53     1.9    3.1   \n",
              "8689                                              <3 <3    53     1.9    3.1   \n",
              "8690                               Madrid Triumphs!! :D    53     1.9    3.1   \n",
              "8691                  A small piece of heaven on earth.    53     1.9    3.1   \n",
              "\n",
              "      NRSM  Person         dark_triad  eng_usage_ratio  bng_usage_ratio  \\\n",
              "0        3       2       mach, psycho       100.000000         0.000000   \n",
              "1        3       2       mach, psycho       100.000000         0.000000   \n",
              "2        3       2       mach, psycho        76.470588        17.647059   \n",
              "3        3       2       mach, psycho       100.000000         0.000000   \n",
              "4        3       2       mach, psycho        83.333333        16.666667   \n",
              "...    ...     ...                ...              ...              ...   \n",
              "8687    19     100  psycho, narcisist        71.428571        14.285714   \n",
              "8688    19     100  psycho, narcisist        33.333333        55.555556   \n",
              "8689    19     100  psycho, narcisist        50.000000         0.000000   \n",
              "8690    19     100  psycho, narcisist        50.000000        25.000000   \n",
              "8691    19     100  psycho, narcisist       100.000000         0.000000   \n",
              "\n",
              "      eng_switching_ratio  bng_switching_ratio  Trait  \n",
              "0                0.000000             0.000000      0  \n",
              "1                0.000000             0.000000      0  \n",
              "2               66.666667            33.333333      0  \n",
              "3                0.000000             0.000000      0  \n",
              "4               50.000000            50.000000      0  \n",
              "...                   ...                  ...    ...  \n",
              "8687            50.000000            50.000000      1  \n",
              "8688            60.000000            40.000000      1  \n",
              "8689             0.000000             0.000000      1  \n",
              "8690           100.000000             0.000000      1  \n",
              "8691             0.000000             0.000000      1  \n",
              "\n",
              "[8692 rows x 17 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4705d222-b10a-438b-bedd-37810bce81f3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0.2</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>level_0</th>\n",
              "      <th>index</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>post</th>\n",
              "      <th>Mach</th>\n",
              "      <th>LSRP12</th>\n",
              "      <th>LSRP2</th>\n",
              "      <th>NRSM</th>\n",
              "      <th>Person</th>\n",
              "      <th>dark_triad</th>\n",
              "      <th>eng_usage_ratio</th>\n",
              "      <th>bng_usage_ratio</th>\n",
              "      <th>eng_switching_ratio</th>\n",
              "      <th>bng_switching_ratio</th>\n",
              "      <th>Trait</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>my heart my soul..T-T</td>\n",
              "      <td>68</td>\n",
              "      <td>1.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>mach, psycho</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Free speech is a joke in this country</td>\n",
              "      <td>68</td>\n",
              "      <td>1.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>mach, psycho</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>Make 500 sequels I don't care.Make another Jus...</td>\n",
              "      <td>68</td>\n",
              "      <td>1.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>mach, psycho</td>\n",
              "      <td>76.470588</td>\n",
              "      <td>17.647059</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>Everybody wants a piece of the politically cor...</td>\n",
              "      <td>68</td>\n",
              "      <td>1.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>mach, psycho</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>And that's how a movement dies.</td>\n",
              "      <td>68</td>\n",
              "      <td>1.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>mach, psycho</td>\n",
              "      <td>83.333333</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8687</th>\n",
              "      <td>8687</td>\n",
              "      <td>8687</td>\n",
              "      <td>12710</td>\n",
              "      <td>12745</td>\n",
              "      <td>12745</td>\n",
              "      <td>TWO SUPERHUMANS IN ONE FRAME &lt;3</td>\n",
              "      <td>53</td>\n",
              "      <td>1.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>19</td>\n",
              "      <td>100</td>\n",
              "      <td>psycho, narcisist</td>\n",
              "      <td>71.428571</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8688</th>\n",
              "      <td>8688</td>\n",
              "      <td>8688</td>\n",
              "      <td>12711</td>\n",
              "      <td>12746</td>\n",
              "      <td>12746</td>\n",
              "      <td>Man!!!\\nThe chase- UNBELIEVABLE!! Mushi and Ri...</td>\n",
              "      <td>53</td>\n",
              "      <td>1.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>19</td>\n",
              "      <td>100</td>\n",
              "      <td>psycho, narcisist</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>55.555556</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8689</th>\n",
              "      <td>8689</td>\n",
              "      <td>8689</td>\n",
              "      <td>12713</td>\n",
              "      <td>12748</td>\n",
              "      <td>12748</td>\n",
              "      <td>&lt;3 &lt;3</td>\n",
              "      <td>53</td>\n",
              "      <td>1.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>19</td>\n",
              "      <td>100</td>\n",
              "      <td>psycho, narcisist</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8690</th>\n",
              "      <td>8690</td>\n",
              "      <td>8690</td>\n",
              "      <td>12714</td>\n",
              "      <td>12749</td>\n",
              "      <td>12749</td>\n",
              "      <td>Madrid Triumphs!! :D</td>\n",
              "      <td>53</td>\n",
              "      <td>1.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>19</td>\n",
              "      <td>100</td>\n",
              "      <td>psycho, narcisist</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8691</th>\n",
              "      <td>8691</td>\n",
              "      <td>8691</td>\n",
              "      <td>12715</td>\n",
              "      <td>12750</td>\n",
              "      <td>12750</td>\n",
              "      <td>A small piece of heaven on earth.</td>\n",
              "      <td>53</td>\n",
              "      <td>1.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>19</td>\n",
              "      <td>100</td>\n",
              "      <td>psycho, narcisist</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8692 rows × 17 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4705d222-b10a-438b-bedd-37810bce81f3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4705d222-b10a-438b-bedd-37810bce81f3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4705d222-b10a-438b-bedd-37810bce81f3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data = df, x = 'Trait')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "j4uqGcpQ-kWY",
        "outputId": "8fa307af-35ff-48b9-f789-8c676a1bad64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 725,
              "height": 546
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['Not narcissist', 'Narcissist']"
      ],
      "metadata": {
        "id": "NSmKLuae7KFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.countplot(data =df, x = 'Trait')\n",
        "plt.xlabel('Trait count')\n",
        "ax.set_xticklabels(class_names);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "VDuH-hdM7gtq",
        "outputId": "8c061eee-cc0c-4376-8107-aebaca547df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 725,
              "height": 546
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text Preprocessing"
      ],
      "metadata": {
        "id": "zYyB95nPGkI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the dataset into test,validation and train\n",
        "df_train, df_test = train_test_split(df, test_size= 0.2, random_state=RANDOM_SEED)\n",
        "df_val, df_test = train_test_split(df_test, test_size= 0.5, random_state=RANDOM_SEED)"
      ],
      "metadata": {
        "id": "_a5Sm7y-IMwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape\n",
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "ccbNQVSlIVaN",
        "outputId": "7efb41cd-b496-4e19-cc12-9ccb07463789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0.2  Unnamed: 0.1  level_0  index  Unnamed: 0  \\\n",
              "2588          2588          2588     3613   3621        3621   \n",
              "1844          1844          1844     2538   2546        2546   \n",
              "8176          8176          8176    12110  12145       12145   \n",
              "500            500           500      725    725         725   \n",
              "7202          7202          7202    10746  10757       10757   \n",
              "\n",
              "                                                   post  Mach  LSRP12  LSRP2  \\\n",
              "2588  I am gonna have homemade food.\\nI am gonna sle...    47  0.0625    0.1   \n",
              "1844  Don't know what's more tragic...that i kept lo...    49  0.0625    0.1   \n",
              "8176                                    মদ্রিচ ইজ লাভ ♥    59  4.0000    2.2   \n",
              "500   Hey Girl, Happy Birthday ❤️\\nবুক ভরা ভালোবাসা ...    68  3.3000    1.6   \n",
              "7202  Don't waste the food at least instead of treat...    59  3.0000    3.5   \n",
              "\n",
              "      NRSM  Person               dark_triad  eng_usage_ratio  bng_usage_ratio  \\\n",
              "2588     6      30                     none        68.181818        31.818182   \n",
              "1844     6      22                     none        82.608696        17.391304   \n",
              "8176    18      96  mach, psycho, narcisist        20.000000        60.000000   \n",
              "500     31       7  mach, psycho, narcisist        13.793103        79.310345   \n",
              "7202    15      85  mach, psycho, narcisist        90.000000        10.000000   \n",
              "\n",
              "      eng_switching_ratio  bng_switching_ratio  Trait  \n",
              "2588            50.000000            50.000000      0  \n",
              "1844            42.857143            57.142857      0  \n",
              "8176             0.000000             0.000000      1  \n",
              "500            100.000000             0.000000      1  \n",
              "7202             0.000000           100.000000      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-813cb8df-c4d8-4136-8d60-a750b3ab2912\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0.2</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>level_0</th>\n",
              "      <th>index</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>post</th>\n",
              "      <th>Mach</th>\n",
              "      <th>LSRP12</th>\n",
              "      <th>LSRP2</th>\n",
              "      <th>NRSM</th>\n",
              "      <th>Person</th>\n",
              "      <th>dark_triad</th>\n",
              "      <th>eng_usage_ratio</th>\n",
              "      <th>bng_usage_ratio</th>\n",
              "      <th>eng_switching_ratio</th>\n",
              "      <th>bng_switching_ratio</th>\n",
              "      <th>Trait</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2588</th>\n",
              "      <td>2588</td>\n",
              "      <td>2588</td>\n",
              "      <td>3613</td>\n",
              "      <td>3621</td>\n",
              "      <td>3621</td>\n",
              "      <td>I am gonna have homemade food.\\nI am gonna sle...</td>\n",
              "      <td>47</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.1</td>\n",
              "      <td>6</td>\n",
              "      <td>30</td>\n",
              "      <td>none</td>\n",
              "      <td>68.181818</td>\n",
              "      <td>31.818182</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1844</th>\n",
              "      <td>1844</td>\n",
              "      <td>1844</td>\n",
              "      <td>2538</td>\n",
              "      <td>2546</td>\n",
              "      <td>2546</td>\n",
              "      <td>Don't know what's more tragic...that i kept lo...</td>\n",
              "      <td>49</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.1</td>\n",
              "      <td>6</td>\n",
              "      <td>22</td>\n",
              "      <td>none</td>\n",
              "      <td>82.608696</td>\n",
              "      <td>17.391304</td>\n",
              "      <td>42.857143</td>\n",
              "      <td>57.142857</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8176</th>\n",
              "      <td>8176</td>\n",
              "      <td>8176</td>\n",
              "      <td>12110</td>\n",
              "      <td>12145</td>\n",
              "      <td>12145</td>\n",
              "      <td>মদ্রিচ ইজ লাভ ♥</td>\n",
              "      <td>59</td>\n",
              "      <td>4.0000</td>\n",
              "      <td>2.2</td>\n",
              "      <td>18</td>\n",
              "      <td>96</td>\n",
              "      <td>mach, psycho, narcisist</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>725</td>\n",
              "      <td>725</td>\n",
              "      <td>725</td>\n",
              "      <td>Hey Girl, Happy Birthday ❤️\\nবুক ভরা ভালোবাসা ...</td>\n",
              "      <td>68</td>\n",
              "      <td>3.3000</td>\n",
              "      <td>1.6</td>\n",
              "      <td>31</td>\n",
              "      <td>7</td>\n",
              "      <td>mach, psycho, narcisist</td>\n",
              "      <td>13.793103</td>\n",
              "      <td>79.310345</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7202</th>\n",
              "      <td>7202</td>\n",
              "      <td>7202</td>\n",
              "      <td>10746</td>\n",
              "      <td>10757</td>\n",
              "      <td>10757</td>\n",
              "      <td>Don't waste the food at least instead of treat...</td>\n",
              "      <td>59</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>3.5</td>\n",
              "      <td>15</td>\n",
              "      <td>85</td>\n",
              "      <td>mach, psycho, narcisist</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-813cb8df-c4d8-4136-8d60-a750b3ab2912')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-813cb8df-c4d8-4136-8d60-a750b3ab2912 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-813cb8df-c4d8-4136-8d60-a750b3ab2912');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.shape, df_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feMn05qqIYeG",
        "outputId": "2f695b83-0c61-42f4-a74b-62020efb8645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((870, 17), (869, 17))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRPMMWIEJiND",
        "outputId": "ffb98d9d-6bab-4361-aa50-36122fd3c92c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0.2', 'Unnamed: 0.1', 'level_0', 'index', 'Unnamed: 0',\n",
              "       'post', 'Mach', 'LSRP12', 'LSRP2', 'NRSM', 'Person', 'dark_triad',\n",
              "       'eng_usage_ratio', 'bng_usage_ratio', 'eng_switching_ratio',\n",
              "       'bng_switching_ratio', 'Trait'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
        "\n",
        "MODEL_TYPE = 'xlm-roberta-base'\n",
        "\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained(MODEL_TYPE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "1d39c810e9a440eca3f698e2d5510033",
            "4edaae57eb6b4ac19eec75a4bf92e4ce",
            "f0ddbed0006b46f6b673ed1ce6d17789",
            "7d279d2d7aff49a89c834c7cb236fb76",
            "2f15f0bdcd674cb08400e95174e12452",
            "0473d72da0a64198b87be4e1a81073a0",
            "f62f58ea4e61448aa0bb7ab037314d3a",
            "2f05b4391d4146b48ac3ffe7ddf7d759",
            "15d333d506934956a9a1e62ac8e9d11f",
            "deae2ecc6bd54e6488554e776e422c78",
            "0f76fd3f7f76494c910458fa4772fe3a",
            "ec1ac978cc644959915de165c0b8eac6",
            "07162fae5d084c7b8570ffae478cdf78",
            "2dda46ab510642ca98b74ab9937a68b8",
            "5e8b2952387349648609e184ed8e5834",
            "75bf3ca925be43d7ae1450d5b4aeeb07",
            "c856d3bf2a23495799a1ec9c372d8322",
            "413f83176d7c49cdbab5332db84ebb1e",
            "93ee724fc271486db79ec873441e9566",
            "db55fda2a3c144099813a0f8cdfa70f4",
            "290c926bba4a4fb5bd87dd26032bc984",
            "3d11b46e3aaf46869c329693b9ce7861"
          ]
        },
        "id": "hQ47pyXtnY_F",
        "outputId": "c100523b-b05b-4640-af31-39d454547500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d39c810e9a440eca3f698e2d5510033"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec1ac978cc644959915de165c0b8eac6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30F2QXH1nnvA",
        "outputId": "34149d48-627b-465f-d9e4-51d10160b7b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250002"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.special_tokens_map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ms3SpWXEop4l",
        "outputId": "28223c99-2faa-4bb6-dc5b-0c9f100c9bd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bos_token': '<s>',\n",
              " 'eos_token': '</s>',\n",
              " 'unk_token': '<unk>',\n",
              " 'sep_token': '</s>',\n",
              " 'pad_token': '<pad>',\n",
              " 'cls_token': '<s>',\n",
              " 'mask_token': '<mask>'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('bos_token_id <s>:', tokenizer.bos_token_id)\n",
        "print('eos_token_id </s>:', tokenizer.eos_token_id)\n",
        "print('sep_token_id </s>:', tokenizer.sep_token_id)\n",
        "print('pad_token_id <pad>:', tokenizer.pad_token_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNTKLedJou6J",
        "outputId": "3269ca0a-36a9-4f02-dc12-30009cedf487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bos_token_id <s>: 0\n",
            "eos_token_id </s>: 2\n",
            "sep_token_id </s>: 2\n",
            "pad_token_id <pad>: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 10 # This value could be set as 256, 512 etc.\n",
        "\n",
        "sentence1 = 'Hello there.'\n",
        "\n",
        "encoded_dict = tokenizer.encode_plus(\n",
        "            sentence1,                \n",
        "            add_special_tokens = True,\n",
        "            truncation=True,     \n",
        "            pad_to_max_length = True,\n",
        "            return_attention_mask = True,  \n",
        "            return_tensors = 'pt' # return pytorch tensors\n",
        "       )\n",
        "\n",
        "\n",
        "encoded_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7GJ5by7oy0j",
        "outputId": "a29434a6-a040-4d53-aec5-50ae4e8af29a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    0, 35378,  2685,     5,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# These have already been converted to torch tensors.\n",
        "input_ids = encoded_dict['input_ids'][0]\n",
        "att_mask = encoded_dict['attention_mask'][0]\n",
        "\n",
        "print(input_ids)\n",
        "print(att_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36lCtyxRpDSS",
        "outputId": "54e8906e-2498-4cb7-bab4-c08070e54eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([    0, 35378,  2685,     5,     2])\n",
            "tensor([1, 1, 1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Decoding from tokens"
      ],
      "metadata": {
        "id": "PPzOFxu6pcpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input_ids from above\n",
        "\n",
        "input_ids = encoded_dict['input_ids'][0]\n",
        "\n",
        "print(input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvfQZkcgpOHe",
        "outputId": "e6abc5ad-bfeb-47d8-ed8f-37586c656ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([    0, 35378,  2685,     5,     2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = tokenizer.decode(input_ids, skip_special_tokens=False)\n",
        "\n",
        "b = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
        "\n",
        "\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYSoHkGspXAO",
        "outputId": "86818ff9-879a-44b5-91d5-20c82f0140c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> Hello there.</s>\n",
            "Hello there.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Overflowing tokens and Stride\n",
        "MAX_LEN = 15 # This value could be set as 256, 512 etc.\n",
        "\n",
        "sentence1 = 'Hello there. How are you? Have a nice day. This is a test?'\n",
        "\n",
        "\n",
        "encoded_dict = tokenizer.encode_plus(\n",
        "            sentence1,                \n",
        "            max_length = MAX_LEN,\n",
        "            stride=0,\n",
        "            pad_to_max_length = True,\n",
        "            return_overflowing_tokens=True,\n",
        "       )\n",
        "\n",
        "\n",
        "encoded_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAsdwdJrpaWP",
        "outputId": "f5328e0f-1ba6-40ed-c60a-6c7ea66b7303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'overflowing_tokens': [83, 10, 3034, 32], 'num_truncated_tokens': 4, 'input_ids': [0, 35378, 2685, 5, 11249, 621, 398, 32, 31901, 10, 26267, 5155, 5, 3293, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 15 # This value could be set as 256, 512 etc.\n",
        "\n",
        "sentence1 = 'Hello there. How are you? Have a nice day. This is a test?'\n",
        "\n",
        "\n",
        "encoded_dict = tokenizer.encode_plus(\n",
        "            sentence1,                \n",
        "            max_length = MAX_LEN,\n",
        "            stride=3,\n",
        "            pad_to_max_length = True,\n",
        "            return_overflowing_tokens=True,\n",
        "       )\n",
        "\n",
        "\n",
        "encoded_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1a-RtJfqA1D",
        "outputId": "3e668160-e65d-4edc-b817-a117a283b5f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'overflowing_tokens': [5155, 5, 3293, 83, 10, 3034, 32], 'num_truncated_tokens': 4, 'input_ids': [0, 35378, 2685, 5, 11249, 621, 398, 32, 31901, 10, 26267, 5155, 5, 3293, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here you can see the overlap.\n",
        "\n",
        "print(encoded_dict['input_ids'])\n",
        "print(encoded_dict['overflowing_tokens'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCPAGbRvqGMJ",
        "outputId": "325624dd-f26d-474f-bd64-f9862f834607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 35378, 2685, 5, 11249, 621, 398, 32, 31901, 10, 26267, 5155, 5, 3293, 2]\n",
            "[5155, 5, 3293, 83, 10, 3034, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_TYPE = 'xlm-roberta-base'\n",
        "\n",
        "\n",
        "L_RATE = 2e-5\n",
        "MAX_LEN = 256\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "BATCH_SIZE = 32\n"
      ],
      "metadata": {
        "id": "ZZxkfa7B1hEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "16OAm6_J135B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzbu47PN2ED4",
        "outputId": "292df83a-b746-4320-f290-a4da13d48b4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
        "\n",
        "# xlm-roberta-large\n",
        "print('Loading XLMRoberta tokenizer...')\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained(MODEL_TYPE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptzk_WbP2HoA",
        "outputId": "230880af-723b-4da2-ea7a-639112c8abbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading XLMRoberta tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train.reset_index(drop=True)\n",
        "df_val = df_val.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "oGlutdhN2Ogz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CompDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self.df_data = df\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # get the sentence from the dataframe\n",
        "        sentence1 = self.df_data.loc[index, 'post']\n",
        "\n",
        "        # Process the sentence\n",
        "        # ---------------------\n",
        "\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                    sentence1,                      # Sentences to encode.\n",
        "                    add_special_tokens = True,      # Add the special tokens.\n",
        "                    max_length = MAX_LEN,           # Pad & truncate all sentences.\n",
        "                    pad_to_max_length = True,\n",
        "                    return_attention_mask = True,   # Construct attn. masks.\n",
        "                    return_tensors = 'pt',          # Return pytorch tensors.\n",
        "               )\n",
        "        \n",
        "        # These are torch tensors.\n",
        "        padded_token_list = encoded_dict['input_ids'][0]\n",
        "        att_mask = encoded_dict['attention_mask'][0]\n",
        "        \n",
        "        # Convert the target to a torch tensor\n",
        "        target = torch.tensor(self.df_data.loc[index, 'Trait'])\n",
        "\n",
        "        sample = (padded_token_list, att_mask, target)\n",
        "\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df_data)"
      ],
      "metadata": {
        "id": "Y7o-uQBT2XWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self.df_data = df\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # get the sentence from the dataframe\n",
        "        sentence1 = self.df_data.loc[index, 'post']\n",
        "\n",
        "        # Process the sentence\n",
        "        # ---------------------\n",
        "\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                    sentence1,                      # Sentence to encode.\n",
        "                    add_special_tokens = True,      # Add the special tokens.\n",
        "                    truncation=True,           # Pad & truncate all sentences.\n",
        "                    padding=True,\n",
        "                    return_attention_mask = True,   # Construct attn. masks.\n",
        "                    return_tensors = 'pt',          # Return pytorch tensors.\n",
        "               )\n",
        "        \n",
        "        # These are torch tensors.\n",
        "        padded_token_list = encoded_dict['input_ids'][0]\n",
        "        att_mask = encoded_dict['attention_mask'][0]\n",
        "        \n",
        "               \n",
        "\n",
        "        sample = (padded_token_list, att_mask)\n",
        "\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df_data)"
      ],
      "metadata": {
        "id": "Or68tUWN32fP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the dataloader"
      ],
      "metadata": {
        "id": "8EFttr944ZE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = CompDataset(df_train)\n",
        "val_data = CompDataset(df_val)\n",
        "test_data = TestDataset(df_test)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=True,\n",
        "                                       num_workers=2)\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(val_data,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=True,\n",
        "                                       num_workers=2)\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(test_data,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=False,\n",
        "                                       num_workers=2)\n",
        "\n",
        "\n",
        "\n",
        "print(len(train_dataloader))\n",
        "print(len(val_dataloader))\n",
        "print(len(test_dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sr_2x6RI4Rhv",
        "outputId": "6f0ef418-c49f-441c-fff0-25f7cbb7ef58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "218\n",
            "28\n",
            "28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_token_list, att_mask, target = next(iter(train_dataloader))\n",
        "\n",
        "print(padded_token_list.shape)\n",
        "print(att_mask.shape)\n",
        "print(target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_23D7fz5bsQ",
        "outputId": "763fe38c-f319-4367-b6d3-b286c43b86ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 256])\n",
            "torch.Size([32, 256])\n",
            "torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get one val batch\n",
        "\n",
        "padded_token_list, att_mask, target = next(iter(val_dataloader))\n",
        "\n",
        "print(padded_token_list.shape)\n",
        "print(att_mask.shape)\n",
        "print(target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-456kqpw6DoL",
        "outputId": "711c55bd-3505-476f-f943-9adb928d248e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 256])\n",
            "torch.Size([32, 256])\n",
            "torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get one val batch\n",
        "\n",
        "padded_token_list, att_mask, target = next(iter(val_dataloader))\n",
        "\n",
        "print(padded_token_list.shape)\n",
        "print(att_mask.shape)\n",
        "print(target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8O5Y4Dz6TIO",
        "outputId": "7d2cd24c-436a-474c-99f8-f1cafd12f20a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 256])\n",
            "torch.Size([32, 256])\n",
            "torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Define the Model"
      ],
      "metadata": {
        "id": "DluueaYn6dHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import XLMRobertaForSequenceClassification\n",
        "\n",
        "model = XLMRobertaForSequenceClassification.from_pretrained(\n",
        "    MODEL_TYPE, \n",
        "    num_labels = 2, # The number of output labels. 2 for binary classification.\n",
        ")\n",
        "\n",
        "# Send the model to the device.\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920,
          "referenced_widgets": [
            "c86f382f9f074fbeb5f1ff1cd09343e7",
            "898d8af4a7324c21885612734df7762e",
            "2b11ad598a7843fbb1cd3f7d92b4727a",
            "86ae1291eb53462db3e571c4a787c6d8",
            "1ce3b0039f7f49e6a14ad03c7111215c",
            "0ca1df3c5edf4a2fbc5ee43884eefe98",
            "49b496fbb9d34ddead3703ac3d981a81",
            "2d22f8cee19344fda3528eabd20fb90f",
            "da36acd1a1ce4c058e20bf05ab907335",
            "5938ae7223324ea6bd384bad962fe078",
            "0ca198eb0aa44d4999a721fd4c0e9fc6"
          ]
        },
        "id": "F5e8NyVX6Y9C",
        "outputId": "4eb78aac-b44c-480b-8dc5-b5e16d19f147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c86f382f9f074fbeb5f1ff1cd09343e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLMRobertaForSequenceClassification(\n",
              "  (roberta): XLMRobertaModel(\n",
              "    (embeddings): XLMRobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): XLMRobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): XLMRobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a batch of train samples\n",
        "# We will set a small batch size of 8 so that the model's output can be easily displayed.\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data,\n",
        "                                        batch_size=8,\n",
        "                                        shuffle=True,\n",
        "                                       num_workers=2)\n",
        "\n",
        "b_input_ids, b_input_mask, b_labels = next(iter(train_dataloader))\n",
        "\n",
        "print(b_input_ids.shape)\n",
        "print(b_input_mask.shape)\n",
        "print(b_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF8DSOM96yYo",
        "outputId": "66e061d1-d57f-4c3a-c70c-57ed9025f7ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass a batch of train samples to the model.\n",
        "\n",
        "batch = next(iter(train_dataloader))\n",
        "\n",
        "# Send the data to the device\n",
        "b_input_ids = batch[0].to(device)\n",
        "b_input_mask = batch[1].to(device)\n",
        "b_labels = batch[2].to(device)\n",
        "\n",
        "# Run the model\n",
        "outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "# The ouput is a tuple (loss, preds).\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4mw4pta7FGg",
        "outputId": "da51fcc5-9bc1-47c0-ce73-07e5368a82ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutput(loss=tensor(0.7087, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.1099,  0.1915],\n",
              "        [-0.0876,  0.1736],\n",
              "        [-0.0911,  0.1600],\n",
              "        [-0.1454,  0.1958],\n",
              "        [-0.0965,  0.1772],\n",
              "        [-0.0942,  0.1957],\n",
              "        [-0.0713,  0.1561],\n",
              "        [-0.1521,  0.2302]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWk-02IM7Oqd",
        "outputId": "1bf19a32-a4b7-4ce0-90ad-325eb0a42b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutput(loss=tensor(0.7087, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.1099,  0.1915],\n",
              "        [-0.0876,  0.1736],\n",
              "        [-0.0911,  0.1600],\n",
              "        [-0.1454,  0.1958],\n",
              "        [-0.0965,  0.1772],\n",
              "        [-0.0942,  0.1957],\n",
              "        [-0.0713,  0.1561],\n",
              "        [-0.1521,  0.2302]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The output is a tuple: (loss, preds)\n",
        "\n",
        "len(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkMcfOyQ7TGG",
        "outputId": "789a00b1-ec42-4bb7-f30e-c91c967a974b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loss = output[0], prediction = output[1]\n",
        "\n",
        "preds = outputs[1].detach().cpu().numpy()\n",
        "\n",
        "y_true = b_labels.detach().cpu().numpy()\n",
        "y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5217jrI7uia",
        "outputId": "7699d021-c491-44f7-ac5b-1483319981c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from transformers import AdamW"
      ],
      "metadata": {
        "id": "tlrty0MN8rbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #This is the accuracy without fine tuning.\n",
        "\n",
        "val_acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "val_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRHqcaCJ8P1_",
        "outputId": "e57dba98-7eae-4431-d52d-e77bfbdb6fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The loss and preds are Torch tensors\n",
        "\n",
        "print(type(outputs[0]))\n",
        "print(type(outputs[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voUcdJsB8StJ",
        "outputId": "94804a34-b2e4-4590-d3d6-2b565ec91db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the optimizer\n",
        "optimizer = AdamW(model.parameters(),lr = L_RATE, eps = 1e-8 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gt5H6bqt82x0",
        "outputId": "35d338b1-a936-4153-e6ee-cedca80203d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train the Model"
      ],
      "metadata": {
        "id": "MhajwLRb89zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the dataloaders.\n",
        "\n",
        "train_data = CompDataset(df_train)\n",
        "val_data = CompDataset(df_val)\n",
        "test_data = TestDataset(df_test)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=True,\n",
        "                                       num_workers=2)\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(val_data,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=True,\n",
        "                                       num_workers=2)\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(test_data,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=False,\n",
        "                                       num_workers=2)\n",
        "\n",
        "\n",
        "\n",
        "print(len(train_dataloader))\n",
        "print(len(val_dataloader))\n",
        "print(len(test_dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ydkrgudy87aF",
        "outputId": "9395ef2c-a147-4508-df1b-6d12b4861eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "218\n",
            "28\n",
            "28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "UKAJA-4d90BM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "# Set the seed.\n",
        "seed_val = 101\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "\n",
        "# For each epoch...\n",
        "for epoch in range(0, NUM_EPOCHS):\n",
        "    \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch + 1, NUM_EPOCHS))\n",
        "    \n",
        "\n",
        "    stacked_val_labels = []\n",
        "    targets_list = []\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    print('Training...')\n",
        "    \n",
        "    # put the model into train mode\n",
        "    model.train()\n",
        "    \n",
        "    # This turns gradient calculations on and off.\n",
        "    torch.set_grad_enabled(True)\n",
        "\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "        \n",
        "        train_status = 'Batch ' + str(i) + ' of ' + str(len(train_dataloader))\n",
        "        \n",
        "        print(train_status, end='\\r')\n",
        "\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "\n",
        "        outputs = model(b_input_ids, \n",
        "                    attention_mask=b_input_mask,\n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # Get the loss from the outputs tuple: (loss, logits)\n",
        "        loss = outputs[0]\n",
        "        \n",
        "        # Convert the loss from a torch tensor to a number.\n",
        "        # Calculate the total loss.\n",
        "        total_train_loss = total_train_loss + loss.item()\n",
        "        \n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "        \n",
        "        \n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        \n",
        "        \n",
        "        # Use the optimizer to update the weights.\n",
        "        \n",
        "        # Optimizer for GPU\n",
        "        optimizer.step() \n",
        "        \n",
        "        # Optimizer for TPU\n",
        "        # https://pytorch.org/xla/\n",
        "        #xm.optimizer_step(optimizer, barrier=True)\n",
        "\n",
        "    \n",
        "    print('Train loss:' ,total_train_loss)\n",
        "\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    \n",
        "    print('\\nValidation...')\n",
        "\n",
        "    # Put the model in evaluation mode.\n",
        "    model.eval()\n",
        "\n",
        "    # Turn off the gradient calculations.\n",
        "    # This tells the model not to compute or store gradients.\n",
        "    # This step saves memory and speeds up validation.\n",
        "    torch.set_grad_enabled(False)\n",
        "    \n",
        "    \n",
        "    # Reset the total loss for this epoch.\n",
        "    total_val_loss = 0\n",
        "    \n",
        "\n",
        "    for j, batch in enumerate(val_dataloader):\n",
        "        \n",
        "        val_status = 'Batch ' + str(j) + ' of ' + str(len(val_dataloader))\n",
        "        \n",
        "        print(val_status, end='\\r')\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)      \n",
        "\n",
        "\n",
        "        outputs = model(b_input_ids, \n",
        "                attention_mask=b_input_mask, \n",
        "                labels=b_labels)\n",
        "        \n",
        "        # Get the loss from the outputs tuple: (loss, logits)\n",
        "        loss = outputs[0]\n",
        "        \n",
        "        # Convert the loss from a torch tensor to a number.\n",
        "        # Calculate the total loss.\n",
        "        total_val_loss = total_val_loss + loss.item()\n",
        "        \n",
        "\n",
        "        # Get the preds\n",
        "        preds = outputs[1]\n",
        "\n",
        "\n",
        "        # Move preds to the CPU\n",
        "        val_preds = preds.detach().cpu().numpy()\n",
        "        \n",
        "        # Move the labels to the cpu\n",
        "        targets_np = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Append the labels to a numpy list\n",
        "        targets_list.extend(targets_np)\n",
        "\n",
        "        if j == 0:  # first batch\n",
        "            stacked_val_preds = val_preds\n",
        "\n",
        "        else:\n",
        "            stacked_val_preds = np.vstack((stacked_val_preds, val_preds))\n",
        "\n",
        "    \n",
        "    # Calculate the validation accuracy\n",
        "    y_true = targets_list\n",
        "    y_pred = np.argmax(stacked_val_preds, axis=1)\n",
        "    \n",
        "    val_acc = accuracy_score(y_true, y_pred)\n",
        "    \n",
        "    \n",
        "    print('Val loss:' ,total_val_loss)\n",
        "    print('Val acc: ', val_acc)\n",
        "\n",
        "\n",
        "    # Save the Model\n",
        "    torch.save(model.state_dict(), 'model.pt')\n",
        "    \n",
        "    # Use the garbage collector to save memory.\n",
        "    # gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKoUquPm9FCh",
        "outputId": "8fa1d2ac-4acc-426a-ccde-23910f304aec"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 144.66366863250732\n",
            "\n",
            "Validation...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 19.047799289226532\n",
            "Val acc:  0.5926352128883774\n",
            "\n",
            "======== Epoch 2 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 142.69972199201584\n",
            "\n",
            "Validation...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 19.3582221865654\n",
            "Val acc:  0.5903337169159953\n",
            "\n",
            "======== Epoch 3 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 134.9121437370777\n",
            "\n",
            "Validation...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 19.793788343667984\n",
            "Val acc:  0.6237054085155351\n",
            "\n",
            "======== Epoch 4 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 133.62191638350487\n",
            "\n",
            "Validation...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 20.40857094526291\n",
            "Val acc:  0.5834292289988493\n",
            "\n",
            "======== Epoch 5 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 125.73848742246628\n",
            "\n",
            "Validation...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 21.130714297294617\n",
            "Val acc:  0.5926352128883774\n",
            "\n",
            "======== Epoch 6 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 117.18789038062096\n",
            "\n",
            "Validation...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 22.1788649559021\n",
            "Val acc:  0.6087456846950517\n",
            "\n",
            "======== Epoch 7 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 108.57075557112694\n",
            "\n",
            "Validation...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 24.254047751426697\n",
            "Val acc:  0.6248561565017261\n",
            "\n",
            "======== Epoch 8 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 97.5415775179863\n",
            "\n",
            "Validation...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 25.212324172258377\n",
            "Val acc:  0.61795166858458\n",
            "\n",
            "======== Epoch 9 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 88.5114017277956\n",
            "\n",
            "Validation...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 25.58134225010872\n",
            "Val acc:  0.620253164556962\n",
            "\n",
            "======== Epoch 10 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jYBvK0fb9t7k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}